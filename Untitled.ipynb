{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import extract_features\n",
    "from scipy import product\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, n_classes,display_labels):\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    cm = cm\n",
    "    \n",
    "    im_ = ax.imshow(cm, interpolation='nearest', cmap='viridis')\n",
    "    cmap_min, cmap_max = im_.cmap(0), im_.cmap(256)\n",
    "    \n",
    "    text_ = np.empty_like(cm, dtype=object)\n",
    "    values_format = '.2g'\n",
    "\n",
    "    # print text with appropriate color depending on background\n",
    "    thresh = (cm.max() - cm.min()) / 2.\n",
    "    for i, j in product(range(n_classes), range(n_classes)):\n",
    "        color = cmap_max if cm[i, j] < thresh else cmap_min\n",
    "        text_[i, j] = ax.text(j, i,format(cm[i, j], values_format),\n",
    "                                   ha=\"center\", va=\"center\",\n",
    "                                   color=color)\n",
    "        \n",
    "    fig.colorbar(im_, ax=ax)\n",
    "    ax.set(xticks=np.arange(n_classes),\n",
    "           yticks=np.arange(n_classes),\n",
    "           xticklabels=display_labels,\n",
    "           yticklabels=display_labels,\n",
    "           ylabel=\"True label\",\n",
    "           xlabel=\"Predicted label\")\n",
    "\n",
    "    ax.set_ylim((n_classes - 0.5, -0.5))\n",
    "    plt.setp(ax.get_xticklabels(), rotation='vertical')\n",
    "\n",
    "    figure_ = fig\n",
    "    ax_ = ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(X_train, y_train, models, score, cv, refit):\n",
    "    \n",
    "    bestmodels = dict()\n",
    "    for name, value in models.items():\n",
    "        \n",
    "        print('*********** Model: {} ***********'.format(name))\n",
    "\n",
    "        estimator = value['model']\n",
    "        tuned_parameters = value['parameters']\n",
    "        \n",
    "        clf = GridSearchCV(estimator, tuned_parameters, scoring=score, cv=cv, n_jobs=-1,refit=refit)\n",
    "\n",
    "        t_beg = time.time()\n",
    "        clf.fit(X_train_scaled, y_train)\n",
    "        selection_time = time.time() - t_beg\n",
    "\n",
    "        print('El tiempo de selección fue: {:0.3f}'.format(selection_time))\n",
    "        print(\"Los mejores parámetros son:\")\n",
    "        print(clf.best_params_)\n",
    "\n",
    "        bestmodels[name] = dict()\n",
    "        bestmodels[name]['bestModel'] = clf.best_estimator_\n",
    "        bestmodels[name]['bestParams'] = clf.best_params_\n",
    "        bestmodels[name]['bestScore'] = clf.best_score_\n",
    "        bestmodels[name]['selectionTime'] = selection_time\n",
    "\n",
    "        for metric in score:\n",
    "            mean_name = 'mean_test_{}'.format(metric)\n",
    "            std_name = 'std_test_{}'.format(metric)\n",
    "\n",
    "            idx_mean_metric = np.argmax(clf.cv_results_[mean_name])\n",
    "            idx_std_metric = np.argmax(clf.cv_results_[std_name])\n",
    "\n",
    "            mean = clf.cv_results_[mean_name][idx_mean_metric]\n",
    "            std = clf.cv_results_[std_name][idx_std_metric]\n",
    "\n",
    "            bestmodels[name]['mean_{}'.format(metric)] = mean\n",
    "            bestmodels[name]['std_{}'.format(metric)] = std\n",
    "\n",
    "    return bestmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = extract_features.matriz_features()\n",
    "X = full_data[:,:-1]\n",
    "y = full_data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********** Model: SVM ***********\n",
      "El tiempo de selección fue: 7738.368\n",
      "Los mejores parámetros son:\n",
      "{'C': 10, 'decision_function_shape': 'ovr', 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "*********** Model: MLP ***********\n",
      "El tiempo de selección fue: 983.347\n",
      "Los mejores parámetros son:\n",
      "{'activation': 'relu', 'hidden_layer_sizes': 20, 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "*********** Model: LINEAR ***********\n",
      "El tiempo de selección fue: 519.989\n",
      "Los mejores parámetros son:\n",
      "{'max_iter': 150, 'multi_class': 'multinomial', 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "*********** Model: RANDOM FOREST ***********\n",
      "El tiempo de selección fue: 349.465\n",
      "Los mejores parámetros son:\n",
      "{'bootstrap': True, 'criterion': 'gini', 'max_features': 'sqrt', 'max_samples': 0.75, 'n_estimators': 45}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "models = {\n",
    "    'SVM': {\n",
    "        'model':SVC(),\n",
    "        'parameters':[\n",
    "            {'C': [0.001,0.01,0.1,1,10], 'kernel': ['linear'], 'decision_function_shape':['ovr']},\n",
    "            {'C': [0.001,0.01,0.1,1,10], 'gamma': [0.0001, 0.001,0.01,0.1,1], 'kernel': ['rbf'], 'decision_function_shape':['ovr']}\n",
    "        ]\n",
    "    },\n",
    "    'MLP': {\n",
    "        'model': MLPClassifier(),\n",
    "        'parameters': [\n",
    "            {'hidden_layer_sizes': [(5),(5,10,5),(5,10,20,10,5),(10),(10,20,10),(20)],\n",
    "             'activation': ['tanh','relu','logistic'], 'solver': ['adam'], 'learning_rate': [0.001,0.01]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "models = {\n",
    "    'SVM': {\n",
    "        'model':SVC(),\n",
    "        'parameters':[\n",
    "            {'C': [0.01,0.1,1,10], 'kernel': ['linear'], 'decision_function_shape':['ovr']},\n",
    "            {'C': [0.01,0.1,1,10], 'gamma': ['scale','auto',0.01,0.1], 'kernel': ['rbf'], 'decision_function_shape':['ovr']}\n",
    "        ]\n",
    "    },\n",
    "    'MLP': {\n",
    "        'model': MLPClassifier(),\n",
    "        'parameters': [\n",
    "            {'hidden_layer_sizes': [(5),(5,10,5),(5,10,20,10,5),(10),(10,20,10),(20)],\n",
    "             'activation': ['tanh','relu','logistic'], 'solver': ['adam'], 'learning_rate': ['constant'],\n",
    "             'learning_rate_init': [0.001,0.01]\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    'LINEAR': {\n",
    "        'model': LogisticRegression(n_jobs=-1),\n",
    "        'parameters': [\n",
    "            {'penalty': ['elasticnet'], 'solver': ['saga'], 'multi_class': ['multinomial', 'ovr'], 'C': [0.01, 0.1, 1],\n",
    "             'l1_ratio': [0, 0.25], 'max_iter': [100, 150]},\n",
    "            {'penalty': ['l1', 'l2'], 'solver': ['saga'], 'multi_class': ['multinomial', 'ovr'], 'C': [0.01, 0.1, 1],\n",
    "             'max_iter': [100, 150]},\n",
    "            {'penalty': ['none'], 'solver': ['saga', 'lbfgs'], 'multi_class': ['multinomial', 'ovr'],\n",
    "             'max_iter': [100, 150]}\n",
    "        ]\n",
    "    },\n",
    "    'RANDOM FOREST':{\n",
    "        'model': RandomForestClassifier(n_jobs=-1),\n",
    "        'parameters':[\n",
    "            {'n_estimators': [5,15,45], 'criterion': ['gini','entropy'],'max_features':['sqrt','log2'],\n",
    "             'bootstrap': [True],'max_samples':[0.25,0.5,0.75]},\n",
    "            {'n_estimators': [5,15,45], 'criterion': ['gini','entropy'], 'max_features':['sqrt','log2'],\n",
    "             'bootstrap': [False]}\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "scoring = {'Accuracy': 'accuracy',\n",
    "           'Precision': 'precision_macro',\n",
    "           'Recall': 'recall_macro',\n",
    "           'F1': 'f1_macro'}\n",
    "\n",
    "refit = 'Recall'\n",
    "\n",
    "bestmodels = grid_search(X_train_scaled,y_train,models,cv=10,score=scoring,refit=refit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bestmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************SVM***************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.41      0.44       933\n",
      "           1       0.46      0.42      0.44       913\n",
      "           2       0.44      0.52      0.48       854\n",
      "\n",
      "    accuracy                           0.45      2700\n",
      "   macro avg       0.45      0.45      0.45      2700\n",
      "weighted avg       0.45      0.45      0.45      2700\n",
      "\n",
      "[[385 252 296]\n",
      " [249 387 277]\n",
      " [202 206 446]]\n",
      "***************MLP***************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.51      0.48       933\n",
      "           1       0.46      0.37      0.41       913\n",
      "           2       0.46      0.50      0.48       854\n",
      "\n",
      "    accuracy                           0.46      2700\n",
      "   macro avg       0.46      0.46      0.45      2700\n",
      "weighted avg       0.46      0.46      0.45      2700\n",
      "\n",
      "[[474 214 245]\n",
      " [330 335 248]\n",
      " [248 183 423]]\n",
      "***************LINEAR***************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.39      0.42       933\n",
      "           1       0.43      0.37      0.40       913\n",
      "           2       0.42      0.54      0.47       854\n",
      "\n",
      "    accuracy                           0.43      2700\n",
      "   macro avg       0.43      0.43      0.43      2700\n",
      "weighted avg       0.43      0.43      0.43      2700\n",
      "\n",
      "[[360 254 319]\n",
      " [255 342 316]\n",
      " [185 206 463]]\n",
      "***************RANDOM FOREST***************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.43      0.43       933\n",
      "           1       0.42      0.41      0.41       913\n",
      "           2       0.41      0.43      0.42       854\n",
      "\n",
      "    accuracy                           0.42      2700\n",
      "   macro avg       0.42      0.42      0.42      2700\n",
      "weighted avg       0.42      0.42      0.42      2700\n",
      "\n",
      "[[399 278 256]\n",
      " [263 373 277]\n",
      " [244 242 368]]\n"
     ]
    }
   ],
   "source": [
    "num_classes = 3\n",
    "for name, value in bestmodels.items():\n",
    "    print('***************{}***************'.format(name))\n",
    "    y_true, y_pred = y_test, value['bestModel'].predict(X_test_scaled)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    ####AQUI EL PLOT####\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=['0','1','2'])\n",
    "    print (cm)\n",
    "    #plot_confusion_matrix(cm, num_classes,['fat','fit','half'])\n",
    "    ####HASTA AQUI EL PLOT####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SVM': {'bestModel': SVC(C=10, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "      decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "      max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "      tol=0.001, verbose=False),\n",
       "  'bestParams': {'C': 10,\n",
       "   'decision_function_shape': 'ovr',\n",
       "   'gamma': 'scale',\n",
       "   'kernel': 'rbf'},\n",
       "  'bestScore': 0.44577588034240795,\n",
       "  'selectionTime': 7738.368471860886,\n",
       "  'mean_Accuracy': 0.44588477366255147,\n",
       "  'std_Accuracy': 0.009516410855168137,\n",
       "  'mean_Precision': 0.44603912039772375,\n",
       "  'std_Precision': 0.009332187388607855,\n",
       "  'mean_Recall': 0.44577588034240795,\n",
       "  'std_Recall': 0.009504917062314187,\n",
       "  'mean_F1': 0.44526496164233426,\n",
       "  'std_F1': 0.009213066851704385},\n",
       " 'MLP': {'bestModel': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "                beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "                hidden_layer_sizes=20, learning_rate='constant',\n",
       "                learning_rate_init=0.01, max_fun=15000, max_iter=200,\n",
       "                momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "                power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "                tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "                warm_start=False),\n",
       "  'bestParams': {'activation': 'relu',\n",
       "   'hidden_layer_sizes': 20,\n",
       "   'learning_rate': 'constant',\n",
       "   'learning_rate_init': 0.01,\n",
       "   'solver': 'adam'},\n",
       "  'bestScore': 0.4418166599930412,\n",
       "  'selectionTime': 983.3466796875,\n",
       "  'mean_Accuracy': 0.44189300411522636,\n",
       "  'std_Accuracy': 0.027107474126457642,\n",
       "  'mean_Precision': 0.4426246691660632,\n",
       "  'std_Precision': 0.09862487051780812,\n",
       "  'mean_Recall': 0.4418166599930412,\n",
       "  'std_Recall': 0.027646422606571224,\n",
       "  'mean_F1': 0.4402254822573012,\n",
       "  'std_F1': 0.0767495241823226},\n",
       " 'LINEAR': {'bestModel': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                     intercept_scaling=1, l1_ratio=None, max_iter=150,\n",
       "                     multi_class='multinomial', n_jobs=-1, penalty='none',\n",
       "                     random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                     warm_start=False),\n",
       "  'bestParams': {'max_iter': 150,\n",
       "   'multi_class': 'multinomial',\n",
       "   'penalty': 'none',\n",
       "   'solver': 'lbfgs'},\n",
       "  'bestScore': 0.4262582129404902,\n",
       "  'selectionTime': 519.9894645214081,\n",
       "  'mean_Accuracy': 0.42650205761316873,\n",
       "  'std_Accuracy': 0.010575491165693177,\n",
       "  'mean_Precision': 0.42605638415151087,\n",
       "  'std_Precision': 0.010249685767911795,\n",
       "  'mean_Recall': 0.4262582129404902,\n",
       "  'std_Recall': 0.010557649909068736,\n",
       "  'mean_F1': 0.4241818979126976,\n",
       "  'std_F1': 0.010386733866209728},\n",
       " 'RANDOM FOREST': {'bestModel': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                         criterion='gini', max_depth=None, max_features='sqrt',\n",
       "                         max_leaf_nodes=None, max_samples=0.75,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, n_estimators=45, n_jobs=-1,\n",
       "                         oob_score=False, random_state=None, verbose=0,\n",
       "                         warm_start=False),\n",
       "  'bestParams': {'bootstrap': True,\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'sqrt',\n",
       "   'max_samples': 0.75,\n",
       "   'n_estimators': 45},\n",
       "  'bestScore': 0.4079694841034792,\n",
       "  'selectionTime': 349.46507239341736,\n",
       "  'mean_Accuracy': 0.4079835390946502,\n",
       "  'std_Accuracy': 0.01296191778397996,\n",
       "  'mean_Precision': 0.4079080047186287,\n",
       "  'std_Precision': 0.012997428376281794,\n",
       "  'mean_Recall': 0.4079694841034792,\n",
       "  'std_Recall': 0.012970449954704762,\n",
       "  'mean_F1': 0.407828913062541,\n",
       "  'std_F1': 0.012866727076640891}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
